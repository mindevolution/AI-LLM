# è°ƒç”¨æœ¬åœ° Ollama DeepSeek æ¨¡å‹

## ğŸ“‹ å‰ç½®è¦æ±‚

### 1. å®‰è£… Ollama

**macOS:**
```bash
brew install ollama
# æˆ–ä¸‹è½½å®‰è£…åŒ…: https://ollama.ai/download
```

**Linux:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**Windows:**
ä¸‹è½½å®‰è£…åŒ…: https://ollama.ai/download

### 2. å¯åŠ¨ Ollama æœåŠ¡

```bash
ollama serve
```

### 3. æ‹‰å– DeepSeek æ¨¡å‹

```bash
# æ‹‰å– deepseek-chat æ¨¡å‹ï¼ˆæ¨èï¼‰
ollama pull deepseek-chat

# æˆ–æ‹‰å– deepseek-r1 æ¨¡å‹
ollama pull deepseek-r1
```

### 4. å®‰è£… Python ä¾èµ–

```bash
pip install requests ollama
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³• 1: ä½¿ç”¨ requests ç›´æ¥è°ƒç”¨ APIï¼ˆæ¨èç”¨äºå­¦ä¹ ï¼‰

```python
from ollama_deepseek import call_ollama_deepseek_simple

result = call_ollama_deepseek_simple("ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
print(result)
```

**ä¼˜ç‚¹:**
- ä¸ä¾èµ–é¢å¤– SDK
- ä»£ç æ¸…æ™°ï¼Œæ˜“äºç†è§£
- å¯ä»¥è‡ªå®šä¹‰è¯·æ±‚

### æ–¹æ³• 2: ä½¿ç”¨ Ollama Python SDKï¼ˆæ¨èç”¨äºç”Ÿäº§ï¼‰

```python
from ollama_deepseek_sdk import call_deepseek, chat_deepseek

# ç®€å•è°ƒç”¨
result = call_deepseek("ä½ å¥½")

# å¤šè½®å¯¹è¯
messages = [
    {"role": "user", "content": "æˆ‘çš„åå­—æ˜¯å¼ ä¸‰"}
]
response = chat_deepseek(messages)
```

**ä¼˜ç‚¹:**
- å®˜æ–¹ SDKï¼Œæ›´ç¨³å®š
- API æ›´ç®€æ´
- æ”¯æŒæµå¼è¾“å‡º

## ğŸ“ ä»£ç ç¤ºä¾‹

### ç®€å•è°ƒç”¨

```python
import ollama

response = ollama.generate(
    model="deepseek-chat",
    prompt="ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"
)
print(response['response'])
```

### å¤šè½®å¯¹è¯

```python
import ollama

messages = [
    {"role": "user", "content": "æˆ‘çš„åå­—æ˜¯å¼ ä¸‰"}
]

response = ollama.chat(
    model="deepseek-chat",
    messages=messages
)
print(response['message']['content'])

# ç»§ç»­å¯¹è¯
messages.append({"role": "assistant", "content": response['message']['content']})
messages.append({"role": "user", "content": "æˆ‘åˆšæ‰è¯´æˆ‘å«ä»€ä¹ˆï¼Ÿ"})

response = ollama.chat(
    model="deepseek-chat",
    messages=messages
)
print(response['message']['content'])
```

### æµå¼è¾“å‡º

```python
import ollama

messages = [{"role": "user", "content": "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—"}]

stream = ollama.chat(
    model="deepseek-chat",
    messages=messages,
    stream=True
)

for chunk in stream:
    if chunk['message']['content']:
        print(chunk['message']['content'], end='', flush=True)
```

## ğŸ”§ API ç«¯ç‚¹è¯´æ˜

Ollama é»˜è®¤è¿è¡Œåœ¨ `http://localhost:11434`

### ä¸»è¦ API ç«¯ç‚¹ï¼š

1. **ç”Ÿæˆæ–‡æœ¬**: `POST /api/generate`
   ```json
   {
     "model": "deepseek-chat",
     "prompt": "ä½ å¥½",
     "stream": false
   }
   ```

2. **å¯¹è¯**: `POST /api/chat`
   ```json
   {
     "model": "deepseek-chat",
     "messages": [
       {"role": "user", "content": "ä½ å¥½"}
     ],
     "stream": false
   }
   ```

3. **åˆ—å‡ºæ¨¡å‹**: `GET /api/tags`

## ğŸ†š ä¸ DashScope çš„åŒºåˆ«

| ç‰¹æ€§ | Ollama (æœ¬åœ°) | DashScope (äº‘ç«¯) |
|------|--------------|------------------|
| ä½ç½® | æœ¬åœ°è¿è¡Œ | äº‘ç«¯æœåŠ¡ |
| è´¹ç”¨ | å…è´¹ | æŒ‰é‡ä»˜è´¹ |
| é€Ÿåº¦ | å–å†³äºæœ¬åœ°ç¡¬ä»¶ | ç¨³å®šå¿«é€Ÿ |
| éšç§ | å®Œå…¨æœ¬åœ°ï¼Œæ•°æ®ä¸å‡ºæœ¬åœ° | æ•°æ®å‘é€åˆ°äº‘ç«¯ |
| æ¨¡å‹é€‰æ‹© | éœ€è¦æ‰‹åŠ¨æ‹‰å– | ç›´æ¥å¯ç”¨ |
| API Key | ä¸éœ€è¦ | éœ€è¦ |

## ğŸ› å¸¸è§é—®é¢˜

### 1. è¿æ¥é”™è¯¯

**é”™è¯¯**: `ConnectionError: æ— æ³•è¿æ¥åˆ° Ollama`

**è§£å†³**:
```bash
# ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œ
ollama serve

# æˆ–æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:11434/api/tags
```

### 2. æ¨¡å‹ä¸å­˜åœ¨

**é”™è¯¯**: `model 'deepseek-chat' not found`

**è§£å†³**:
```bash
# æ‹‰å–æ¨¡å‹
ollama pull deepseek-chat

# æŸ¥çœ‹å·²å®‰è£…çš„æ¨¡å‹
ollama list
```

### 3. å†…å­˜ä¸è¶³

å¦‚æœæ¨¡å‹å¤ªå¤§ï¼Œå¯ä»¥ï¼š
- ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
- å¢åŠ ç³»ç»Ÿå†…å­˜
- ä½¿ç”¨é‡åŒ–ç‰ˆæœ¬ï¼ˆå¦‚ deepseek-chat:7bï¼‰

## ğŸ“š æ›´å¤šèµ„æº

- [Ollama å®˜æ–¹æ–‡æ¡£](https://github.com/ollama/ollama)
- [Ollama Python SDK](https://github.com/ollama/ollama-python)
- [å¯ç”¨æ¨¡å‹åˆ—è¡¨](https://ollama.com/library)

